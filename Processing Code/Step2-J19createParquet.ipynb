{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214a3df3-261a-4bab-b586-f3dc981cf25a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Step 2 converts each of the different flat files into a parquet file. \n",
    "\n",
    "This program is split up into 2 components:\n",
    "\n",
    "The first half defined that work that remains to be done and puts that work into a random order\n",
    "\n",
    "The second component loops through the work that remains to be done, sees if it hasn't been done yet, and then does it. \n",
    "\n",
    "Work is performe in a random order to allow for multiple processes to be executed at once, if work is being performed in the same order then all of the processes were performing the same work at the same time resulting in a great deal of overlapping work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7f9972-d280-4232-b9ee-a7e11447dfaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/fs/ess/scratch/PAS2164/James2019Parquet/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3947555abbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Build a list of all parquet files already completed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0miList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutLoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0miList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/fs/ess/scratch/PAS2164/James2019Parquet/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "sys.path.insert(1, './.local/lib/python3.9/site-packages')\n",
    "sys.path.insert(1, '/users/PAS2164/lawr47/.local/bin')\n",
    "\n",
    "alarmCol=[\"patientIdPrimary-id\",\"patientIdPrimary-type\",\"patientIdPrimary-authority\",\"patientNameGiven\",\"patientNameFamily\",\"assignedLocationCareArea\",\"assignedLocationRoom\",\"assignedLocationBed\",\"polltime\",\"alarmName\",\"abnormalFlags\",\"inactivationState\",\"sil\",'setLow','setHigh',\"chanValue\"]\n",
    "waveCol=[\"patientIdPrimary-id\",\"patientIdPrimary-type\",\"patientIdPrimary-authority\",\"patientNameGiven\",\"patientNameFamily\",\"assignedLocationCareArea\",\"assignedLocationRoom\",\"assignedLocationBed\",\"polltime\",\"mgname\",\"mgGain\",\"mgHZ\",\"mgwave\",\"mguom\",\"mgsite\",\"mgscale\",\"mginvalid\",\"mgmissing\",\"mgPoints\",\"mgPointsBytes\",\"mgMin\",\"mgMax\",\"mgOffset\"]\n",
    "measureCol=[\"patientIdPrimary-id\",\"patientIdPrimary-type\",\"patientIdPrimary-authority\",\"patientNameGiven\",\"patientNameFamily\",\"assignedLocationCareArea\",\"assignedLocationRoom\",\"assignedLocationBed\",\"polltime\",\"mesname\",\"msite\",\"muom\",\"mtext\"]\n",
    "inLoc=\"/fs/ess/scratch/PAS2164/James2019Out/\"\n",
    "outLoc=\"/fs/ess/scratch/PAS2164/James2019Parquet/\"\n",
    "\n",
    "#Build a list of all parquet files already completed\n",
    "iList=[]\n",
    "for pfile in os.listdir(outLoc):\n",
    "    iList.append(pfile)\n",
    "\n",
    "#For each file in the infolder\n",
    "n=0\n",
    "initList=[]\n",
    "for outFile in os.listdir(inLoc):\n",
    "    if outFile.split(\".\")[-1]==\"tsv\":\n",
    "        newFolder=1\n",
    "        if (outFile.split(\".tsv\")[0]+'.parquet') in iList:\n",
    "            newFolder=0\n",
    "        if newFolder==1:\n",
    "            initList.append(outFile)\n",
    "\n",
    "#Ranzomize the list of work.\n",
    "random.shuffle(initList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e2802-0441-42ee-94bb-334f78964ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs/ess/scratch/PAS2164/Ross2019Parquet/Measurement^none^6RH-E~6004^2019-04-22\n",
      "1000 None\n"
     ]
    }
   ],
   "source": [
    "for outFile in initList:\n",
    "    #If that file is a csv\n",
    "    if outFile.split(\".\")[-1]==\"tsv\":\n",
    "        newFolder=1\n",
    "        #if it's a file that's already been processed, skip it.\n",
    "        if (outFile.split(\".tsv\")[0]+'.parquet') in iList:\n",
    "            newFolder=0\n",
    "        if newFolder==1:\n",
    "            if newFolder==1:\n",
    "                #If this is a new file we're working on...\n",
    "                #determine the file type to assign the schema.\n",
    "                fileType = outFile.split(\"^\")[0]\n",
    "                if fileType==\"Wave\":\n",
    "                    columns=waveCol\n",
    "                if fileType==\"Alarm\":\n",
    "                    columns=alarmCol\n",
    "                if fileType==\"Measurement\":\n",
    "                    columns=measureCol\n",
    "                #Read in the tsv file\n",
    "                df=pd.read_csv(inLoc+outFile,sep='\\t',names=columns,low_memory=False)\n",
    "                #Remove duplicate values\n",
    "                dfu=df.drop_duplicates()\n",
    "                #Output the file as a parquet\n",
    "                dfu.to_parquet(outLoc+outFile.split(\".tsv\")[0]+'.parquet', index=False)\n",
    "                n=n+1\n",
    "                if n%1000==0:\n",
    "                    print(str(n),print(outLoc+outFile.split(\".tsv\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fefe60-16ba-48d2-ad5f-579fc3f9a201",
   "metadata": {},
   "source": [
    "At the end of this program for every flat file that was generated in step 1, there is a parquet file of that flat file in step 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
