{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ea11e4-6531-48ce-86d2-07ed139ffe8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "At this point there is a folder that exists with hundreds of thousands of parquet files that I want to start to combine, first into files by day-type and then into files by type.\n",
    "\n",
    "Similar to in Step 1, files are used identify what work has been done and what work remains to be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662ca0e-dae0-455a-91cf-7ed20035369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import StringType\n",
    "sys.path.insert(1, './.local/lib/python3.9/site-packages')\n",
    "sys.path.insert(1, '/users/PAS2164/lawr47/.local/bin')\n",
    "\n",
    "#define the in and out paths and the start and end files.\n",
    "inLoc='/fs/ess/scratch/PAS2164/James2019Parquet/'\n",
    "parqStart='/fs/ess/scratch/PAS2164/j19ps.txt'\n",
    "parqEnd='/fs/ess/scratch/PAS2164/j19pe.txt'\n",
    "outLoc=\"/fs/ess/scratch/PAS2164/James2019Parquet2/\"\n",
    "\n",
    "#Define a list of file types\n",
    "fileTypeList=[]\n",
    "fileTypeList.append(\"Alarm\")\n",
    "fileTypeList.append(\"Wave\")\n",
    "fileTypeList.append(\"Measurement\")\n",
    "\n",
    "#identify all of the work that there is to do. \n",
    "alarmPathList=[]\n",
    "wavePathList=[]\n",
    "measPathList=[]\n",
    "for inFile in os.listdir(inLoc):\n",
    "    if inFile.split(\".\")[-1]==\"parquet\":\n",
    "        fileType = inFile.split(\"^\")[0]\n",
    "        #print(inFile,fileType)\n",
    "        if fileType==\"Alarm\":\n",
    "            alarmPathList.append(inLoc+inFile)\n",
    "        if fileType==\"Wave\":\n",
    "            wavePathList.append(inLoc+inFile)\n",
    "        if fileType==\"Measurement\":\n",
    "            measPathList.append(inLoc+inFile)\n",
    "fullDateList=[]\n",
    "for file in os.listdir(inLoc):\n",
    "    fullDateList.append(file.split(\"^\")[3].split(\".\")[0])\n",
    "fullDateList=list(set(fullDateList))\n",
    "\n",
    "startedDateList=[]\n",
    "writeStart=open(parqStart)\n",
    "for l in writeStart:\n",
    "    startedDateList.append(l)\n",
    "writeStart.close()\n",
    "\n",
    "#For each Date in the List\n",
    "for date in fullDateList:\n",
    "    for ft in fileTypeList:\n",
    "        newFile=1\n",
    "        startedDateList=[]\n",
    "        writeStart=open(parqStart)\n",
    "        for l in writeStart:\n",
    "            startedDateList.append(l)\n",
    "        writeStart.close()\n",
    "        #Check to see if that date has started\n",
    "        if (date+\",\"+ft+\"\\n\") in startedDateList:\n",
    "            newFile=0\n",
    "        #If it has not started\n",
    "        if newFile==1:\n",
    "            print(date,ft)\n",
    "            #write that you're starting it\n",
    "            writeStart=open(parqStart,'a')\n",
    "            writeStart.write((date+\",\"+ft+\"\\n\"))\n",
    "            writeStart.close()\n",
    "            dfCombine=0\n",
    "            if ft==\"Alarm\":\n",
    "                localPathList=alarmPathList\n",
    "            if ft==\"Wave\":\n",
    "                localPathList=wavePathList\n",
    "            if ft==\"Measurement\":\n",
    "                localPathList=measPathList\n",
    "            for fullfilepath in localPathList:\n",
    "                localDate=(fullfilepath.split(\"^\")[3].split(\".\")[0])\n",
    "                if date==localDate:\n",
    "                    #print(date,fullfilepath)\n",
    "                    try:\n",
    "                        tempdf = spark.read.parquet(fullfilepath)\n",
    "                        if ft==\"Alarm\":\n",
    "                            cast_df = tempdf.select(\n",
    "                            col(\"patientIdPrimary-id\").cast(StringType())\n",
    "                            ,col(\"patientIdPrimary-type\").cast(StringType())\n",
    "                            ,col(\"patientIdPrimary-authority\").cast(StringType())\n",
    "                            ,col(\"patientNameGiven\").cast(StringType())\n",
    "                            ,col(\"patientNameFamily\").cast(StringType())\n",
    "                            ,col(\"assignedLocationCareArea\").cast(StringType())\n",
    "                            ,col(\"assignedLocationRoom\").cast(StringType())\n",
    "                            ,col(\"assignedLocationBed\").cast(StringType())\n",
    "                            ,col(\"polltime\").cast(StringType())\n",
    "                            ,col(\"alarmName\").cast(StringType())\n",
    "                            ,col(\"abnormalFlags\").cast(StringType())\n",
    "                            ,col(\"inactivationState\").cast(StringType())\n",
    "                            ,col(\"sil\").cast(StringType())\n",
    "                            ,col(\"setLow\").cast(StringType())\n",
    "                            ,col(\"setHigh\").cast(StringType())\n",
    "                            ,col(\"chanValue\").cast(StringType()))\n",
    "                        if ft==\"Wave\":\n",
    "                            cast_df = tempdf.select(col(\"patientIdPrimary-id\").cast(StringType())\n",
    "                            ,col(\"patientIdPrimary-type\").cast(StringType())\n",
    "                            ,col(\"patientIdPrimary-authority\").cast(StringType())\n",
    "                            ,col(\"patientNameGiven\").cast(StringType())\n",
    "                            ,col(\"patientNameFamily\").cast(StringType())\n",
    "                            ,col(\"assignedLocationCareArea\").cast(StringType())\n",
    "                            ,col(\"assignedLocationRoom\").cast(StringType())\n",
    "                            ,col(\"assignedLocationBed\").cast(StringType())\n",
    "                            ,col(\"polltime\").cast(StringType())\n",
    "                            ,col(\"mgname\").cast(StringType())\n",
    "                            ,col(\"mgGain\").cast(StringType())\n",
    "                            ,col(\"mgHZ\").cast(StringType())\n",
    "                            ,col(\"mgwave\").cast(StringType())\n",
    "                            ,col(\"mguom\").cast(StringType())\n",
    "                            ,col(\"mgsite\").cast(StringType())\n",
    "                            ,col(\"mgscale\").cast(StringType())\n",
    "                            ,col(\"mginvalid\").cast(StringType())\n",
    "                            ,col(\"mgmissing\").cast(StringType())\n",
    "                            ,col(\"mgPoints\").cast(StringType())\n",
    "                            ,col(\"mgPointsBytes\").cast(StringType())\n",
    "                            ,col(\"mgMin\").cast(StringType())\n",
    "                            ,col(\"mgMax\").cast(StringType())\n",
    "                            ,col(\"mgOffset\").cast(StringType()))\n",
    "                        if ft==\"Measurement\":\n",
    "                            cast_df = tempdf.select(col(\"patientIdPrimary-id\").cast(StringType())\n",
    "                            ,col(\"patientIdPrimary-type\").cast(StringType())\n",
    "                            ,col(\"patientIdPrimary-authority\").cast(StringType())\n",
    "                            ,col(\"patientNameGiven\").cast(StringType())\n",
    "                            ,col(\"patientNameFamily\").cast(StringType())\n",
    "                            ,col(\"assignedLocationCareArea\").cast(StringType())\n",
    "                            ,col(\"assignedLocationRoom\").cast(StringType())\n",
    "                            ,col(\"assignedLocationBed\").cast(StringType())\n",
    "                            ,col(\"polltime\").cast(StringType())\n",
    "                            ,col(\"mesname\").cast(StringType())\n",
    "                            ,col(\"msite\").cast(StringType())\n",
    "                            ,col(\"muom\").cast(StringType())\n",
    "                            ,col(\"mtext\").cast(StringType()))\n",
    "                        if dfCombine==0:\n",
    "                            dfCombine=cast_df\n",
    "                        if dfCombine!=0:\n",
    "                            dfCombine=dfCombine.unionByName(cast_df)\n",
    "                    except:\n",
    "                        print(fullfilepath,\"Corrupt\")\n",
    "            #At this location, dfCombine is the fully combined file and it's ready wo rtie.\n",
    "            outPath=outLoc+\"Ross^\"+ft+\"^\"+str(date)+\".parquet\"\n",
    "            try:\n",
    "                dfCombine.write.option(\"mergeSchema\", \"true\").parquet(outPath)\n",
    "                masterFin=open(parqEnd,'a')\n",
    "                masterFin.write((date+\",\"+ft+\"\\n\"))\n",
    "                masterFin.close()\n",
    "            except:\n",
    "                print(outPath, \"Fail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8324320-511a-47ef-b7af-de5a3f5a60c2",
   "metadata": {},
   "source": [
    "At this point there is a combined file for every day and for every data type. First use resetrepair to rerun the analysis and fix imcompleted files and then the next step is to build a list of each of those types of files and combine them into three big files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032cf120-38d7-45ec-9840-0084e993b5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dailyAlarmPathList=[]\n",
    "dailyWavePathList=[]\n",
    "dailyMeasPathList=[]\n",
    "           \n",
    "for ft in fileTypeList:\n",
    "    for file in os.listdir(outLoc):\n",
    "        if (file.split(\"^\")[1])==ft:\n",
    "            if ft==\"Alarm\":\n",
    "                dailyAlarmPathList.append(outLoc+file)\n",
    "            if ft==\"Wave\":\n",
    "                dailyWavePathList.append(outLoc+file)\n",
    "            if ft==\"Measurement\":\n",
    "                dailyMeasPathList.append(outLoc+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a564199-ec63-45d6-89d3-4965f7feca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAlarmDaily = spark.read.parquet(*dailyAlarmPathList)\n",
    "dfAlarmDaily.write.option(\"mergeSchema\", \"true\").mode(\"overwrite\").parquet('/fs/ess/scratch/PAS2164/James2019Alarm.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8f8b9-eb71-47da-9ac0-53ef383cede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWaveDaily = spark.read.parquet(*dailyWavePathList)\n",
    "dfWaveDaily.write.option(\"mergeSchema\", \"true\").mode(\"overwrite\").parquet('/fs/ess/scratch/PAS2164/James2019Wave.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06466ee9-72ed-4602-a084-bcf228491e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMeasurementDaily = spark.read.parquet(*dailyMeasPathList)\n",
    "dfMeasurementDaily.write.option(\"mergeSchema\", \"true\").mode(\"overwrite\").parquet('/fs/ess/scratch/PAS2164/James2019Measurement.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
